id: github-copilot-aifoundry-promptflow
name: Example Prompt flow for Q&A with RAG context
inputs:
  chat_history:
    type: list
    default: ""
    is_chat_input: false
    is_chat_history: true
  chat_input:
    type: string
    default: ""
    is_chat_input: true
  chat_files:
    type: string
    default: ""
    is_chat_input: false
outputs:
  chat_output:
    type: string
    reference: ${chat_with_context.output}
    is_chat_output: true
nodes:
- name: modify_query_with_history
  type: llm
  source:
    type: code
    path: modify_query_with_history.jinja2
  inputs:
    deployment_name: DeepSeek-R1
    temperature: 0
    top_p: 1
    max_tokens: 1000
    presence_penalty: 0
    frequency_penalty: 0
    chat_files: ${inputs.chat_files}
    chat_history: ${inputs.chat_history}
    chat_input: ${inputs.chat_input}
  provider: AzureOpenAI
  connection: <ai-foundry-aoai-connection-name>
  api: chat
  module: promptflow.tools.aoai
  use_variants: false
- name: lookup
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.common_index_lookup.search
  inputs:
    mlindex_content: >
      embeddings:
        api_base: https://<ai-foundry-hub-name>.openai.azure.com/
        api_type: azure
        api_version: 2023-07-01-preview
        batch_size: '1'
        connection:
          id: /subscriptions/<subscription-id>/resourceGroups/<res-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<project-name>/connections/<ai-foundry-aoai-connection-name>
        connection_type: workspace_connection
        deployment: text-embedding-ada-002
        dimension: 1536
        kind: open_ai
        model: text-embedding-ada-002
        schema_version: '2'
      index:
        api_version: 2024-05-01-preview
        connection:
          id: /subscriptions/<subscription-id>/resourceGroups/<res-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<project-name>/connections/<vector-search-name>
        connection_type: workspace_connection
        endpoint: https://<vector-search-name>.search.windows.net/
        engine: azure-sdk
        field_mapping:
          content: content
          embedding: contentVector
          metadata: meta_json_string
        index: <index-name>
        kind: acs
        semantic_configuration_name: azureml-default
    queries: ${modify_query_with_history.output}
    query_type: Hybrid (vector + keyword)
    top_k: 2
  use_variants: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: ${lookup.output}
  use_variants: false
- name: chat_with_context
  type: llm
  source:
    type: code
    path: chat_with_context.jinja2
  inputs:
    deployment_name: <model-deployment-name>
    temperature: 0
    top_p: 1
    max_tokens: 1000
    presence_penalty: 0
    frequency_penalty: 0
    chat_files: ${inputs.chat_files}
    chat_history: ${inputs.chat_history}
    chat_input: ${inputs.chat_input}
    rag_context: ${generate_prompt_context.output}
  provider: AzureOpenAI
  connection: <ai-foundry-aoai-connection-name>
  api: chat
  module: promptflow.tools.aoai
  use_variants: false
node_variants: {}
environment:
  python_requirements_txt: requirements.txt
